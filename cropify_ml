import streamlit as st
 
# Set page configuration
st.set_page_config(page_title="Cropify", page_icon="üåæ", layout="centered")

# Title and description
st.title("üåæ Cropify ‚Äì Smart Crop Recommender")
st.markdown("Enter the soil and climate parameters below to get the best crop suggestion powered by AI.")

# Sidebar input fields in two columns
with st.form("crop_form"):
    st.subheader("üìä Input Parameters")
    col1, col2 = st.columns(2)

    with col1:
        nitrogen = st.number_input("Nitrogen (N)", min_value=0, max_value=200, value=50)
        phosphorus = st.number_input("Phosphorus (P)", min_value=0, max_value=200, value=50)
        potassium = st.number_input("Potassium (K)", min_value=0, max_value=200, value=50)
        ph = st.number_input("Soil pH", min_value=0.0, max_value=14.0, value=6.5)

    with col2:
        temperature = st.number_input("Temperature (¬∞C)", min_value=0.0, max_value=60.0, value=25.0)
        humidity = st.number_input("Humidity (%)", min_value=0.0, max_value=100.0, value=60.0)
        rainfall = st.number_input("Rainfall (mm)", min_value=0.0, max_value=500.0, value=100.0)

    submitted = st.form_submit_button("üå± Predict Crop")              

# Placeholder result section
if submitted:
    # üöÄ Replace this block with actual model prediction
    # e.g. result = model.predict([[...]])
    mock_result = "Wheat"  # Hardcoded for now
    st.success(f"‚úÖ Recommended Crop: **{mock_result}**")
    st.balloons()


#RANDOM FOREST(TRAINING AND SAVING)
# train_rf_model.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import joblib

# Load your dataset
data = pd.read_csv("crop_dataset.csv")  # Ensure this CSV file is in your working directory

# Separate features and target
X = data.drop("label", axis=1)  # Features
y = data["label"]               # Target variable

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Save the trained model to a file
joblib.dump(rf_model, "rf_crop_model.pkl")
print("‚úÖ Random Forest model trained and saved as 'rf_crop_model.pkl'")


#INTEGRATION OF MODEL IN THE STREAMLIT APP (RANDOM FOREST)
# cropii.py
import streamlit as st
import joblib
import numpy as np

# Load the trained Random Forest model
model = joblib.load("rf_crop_model.pkl")

# Set up the Streamlit app
st.title("üåæ Cropify - Smart Crop Recommendation")

# Create sliders for user input
nitrogen = st.slider("Nitrogen (N)", 0, 140, 70)
phosphorus = st.slider("Phosphorus (P)", 5, 145, 60)
potassium = st.slider("Potassium (K)", 5, 205, 65)
temperature = st.slider("Temperature (¬∞C)", 10, 45, 25)
humidity = st.slider("Humidity (%)", 10, 100, 60)
ph = st.slider("Soil pH", 3.5, 9.5, 6.5)
rainfall = st.slider("Rainfall (mm)", 20.0, 300.0, 100.0)

# Predict the optimal crop when the button is clicked
if st.button("üå± Predict Optimal Crop"):
    # Prepare the input data as a 2D array
    input_data = np.array([[nitrogen, phosphorus, potassium, temperature, humidity, ph, rainfall]])
    
    # Make the prediction
    prediction = model.predict(input_data)[0]
    
    # Display the result
    st.success(f"‚úÖ Recommended Crop: **{prediction}**")


#MLP MODEL (TRAINING AND TESTING)
# train_mlp_model.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
import joblib

# Load your dataset
data = pd.read_csv("crop_dataset.csv")  # Ensure this CSV file is in your working directory

# Separate features and target
X = data.drop("label", axis=1)  # Features
y = data["label"]               # Target variable

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the MLP Classifier
mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)

# Train the model
mlp_model.fit(X_train, y_train)

# Save the trained model to a file
joblib.dump(mlp_model, "mlp_crop_model.pkl")
print("‚úÖ MLP model trained and saved as 'mlp_crop_model.pkl'")

INTEGRATION OF MODEL INTO STREAMLIT(MLP)
# cropii.py
import streamlit as st
import joblib
import numpy as np

# Load the trained MLP model
model = joblib.load("mlp_crop_model.pkl")

# Set up the Streamlit app
st.title("üåæ Cropify - Smart Crop Recommendation")

# Create sliders for user input
nitrogen = st.slider("Nitrogen (N)", 0, 140, 70)
phosphorus = st.slider("Phosphorus (P)", 5, 145, 60)
potassium = st.slider("Potassium (K)", 5, 205, 65)
temperature = st.slider("Temperature (¬∞C)", 10, 45, 25)
humidity = st.slider("Humidity (%)", 10, 100, 60)
ph = st.slider("Soil pH", 3.5, 9.5, 6.5)
rainfall = st.slider("Rainfall (mm)", 20.0, 300.0, 100.0)

# Predict the optimal crop when the button is clicked
if st.button("üå± Predict Optimal Crop"):
    # Prepare the input data as a 2D array
    input_data = np.array([[nitrogen, phosphorus, potassium, temperature, humidity, ph, rainfall]])
    
    # Make the prediction
    prediction = model.predict(input_data)[0]
    
    # Display the result
    st.success(f"‚úÖ Recommended Crop: **{prediction}**")

#TO ADD THE DROPDOWNBOX
#to add the slidebar on the models 
import streamlit as st
import joblib
import numpy as np

# Load all models
models = {
    "Random Forest": joblib.load("rf_crop_model.pkl"),
    "Naive Bayes": joblib.load("nb_crop_model.pkl"),
    "MLP": joblib.load("mlp_crop_model.pkl"),
    "Decision Tree": joblib.load("dt_crop_model.pkl")
}

# Streamlit app title
st.title("üåæ Cropify - Smart Crop Recommendation")

# Model selection dropdown
model_choice = st.selectbox("Choose ML Model", list(models.keys()))
model = models[model_choice]

# Input sliders
nitrogen = st.slider("Nitrogen (N)", 0, 140, 70)
phosphorus = st.slider("Phosphorus (P)", 5, 145, 60)
potassium = st.slider("Potassium (K)", 5, 205, 65)
temperature = st.slider("Temperature (¬∞C)", 10, 45, 25)
humidity = st.slider("Humidity (%)", 10, 100, 60)
ph = st.slider("Soil pH", 3.5, 9.5, 6.5)
rainfall = st.slider("Rainfall (mm)", 20.0, 300.0, 100.0)

# Predict button
if st.button("üå± Predict Optimal Crop"):
    input_data = np.array([[nitrogen, phosphorus, potassium, temperature, humidity, ph, rainfall]])
    prediction = model.predict(input_data)[0]
    st.success(f"‚úÖ Recommended Crop using {model_choice}: **{prediction}**")


#CORRELATION MATRIX CODE (For taking out correlation constant)
import pandas as pd

# Assuming 'df' is your DataFrame and 'label' is the target variable
correlation_matrix = df.corr()
correlation_with_target = correlation_matrix['label'].sort_values(ascending=False)

print(correlation_with_target)


#VISUALISING CORRELATIONS (ON A GRAPHH)
import seaborn as sns
import matplotlib.pyplot as plt

# Heatmap of the correlation matrix
plt.figure(figsize=(10,8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Feature Correlation Matrix')
plt.show()

#DEPLOYING INTO STREAMLIT 
import streamlit as st

st.title("Cropify: Crop Recommendation System")

# Upload dataset
uploaded_file = st.file_uploader("Upload your dataset", type=["csv"])
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.write("Dataset Preview:", df.head())

    # Compute and display correlation matrix
    correlation_matrix = df.corr()
    st.subheader("Correlation Matrix")
    st.write(correlation_matrix)

    # Visualize correlation matrix
    st.subheader("Correlation Heatmap")
    plt.figure(figsize=(10,8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
    st.pyplot(plt)

#ADDING BACKGROUNND ON THE STREAMLIT OF CROPIFY
def add_bg_from_url():
    st.markdown(
         f"""
         <style>
         .stApp {{
             background-image: url("https://images.unsplash.com/photo-1582281298054-e84dd46d1301");
             background-attachment: fixed;
             background-size: cover
         }}
         </style>
         """,
         unsafe_allow_html=True
     )

add_bg_from_url()

import plotly.graph_objects as go

def display_prediction_chart(crop, probability):
    fig = go.Figure(go.Indicator(
        mode = "gauge+number+delta",
        value = probability,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': f"Prediction Confidence for {crop}", 'font': {'size': 18}},
        gauge = {
            'axis': {'range': [0, 100]},
            'bar': {'color': "#4CAF50"},
            'steps': [
                {'range': [0, 50], 'color': "#ffcccc"},
                {'range': [50, 75], 'color': "#ffe0b2"},
                {'range': [75, 100], 'color': "#c8e6c9"}
            ]
        }))
    st.plotly_chart(fig, use_container_width=True)


#USER CITY DETECTON USING IP ADDRESS
import requests

def get_city_from_ip():
    try:
        response = requests.get('https://ipinfo.io/json')
        data = response.json()
        city = data['city']
        return city
    except Exception as e:
        print("Error detecting city:", e)
        return None

# Example usage
city = get_city_from_ip()
print(f"Detected city: {city}")


#DETECTION USING IP ADDRESS 
import requests

def get_location():
    try:
        response = requests.get("https://ipinfo.io/json")
        data = response.json()
        city = data.get("city", "Unknown")
        region = data.get("region", "Unknown")
        country = data.get("country", "Unknown")

        return city, region, country
    except Exception as e:
        return "Error", "Error", "Error"

# TEST: Show city in terminal
city, region, country = get_location()
print(f"üìç You are in {city}, {region}, {country}")



 













 
